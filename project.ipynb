{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.exposure import histogram\n",
    "import os\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset=[]\n",
    "testset=[]\n",
    "labels=[]\n",
    "histSet=[]\n",
    "trainingsetHist=[]\n",
    "testsetHist=[]\n",
    "predictedLabels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(images,label,isTrain=0,numPoints=38,radius=10, eps=1e-7):\n",
    "    global trainingsetHist\n",
    "    global testsetHist\n",
    "    for image in images:\n",
    "        lbp = local_binary_pattern(image, numPoints, radius, method= \"uniform\" ) \n",
    "        (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, numPoints + 3),range=(0, numPoints + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        if isTrain==0:\n",
    "            trainingsetHist.append([hist,label])\n",
    "        else:\n",
    "            testsetHist.append(hist)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutLines(gray):\n",
    "    edges = cv2.Canny(gray,90,100,apertureSize = 3)\n",
    "    minLineLength=55\n",
    "    lines = cv2.HoughLinesP(image=edges,rho=1,theta=np.pi/180, threshold=100,lines=np.array([]), minLineLength=minLineLength,maxLineGap=0)\n",
    " \n",
    "    linesNew=[ line[0][1] for line in lines if line[0][1]==line[0][3]]\n",
    "    linesNew=sorted(linesNew)\n",
    "    finalList=[linesNew[0]]\n",
    "    for i in range(1,len(linesNew)):\n",
    "        if linesNew[i]-linesNew[i-1]>=100:\n",
    "            finalList.append(linesNew[i])\n",
    "    return gray[finalList[1]:finalList[2],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_segments(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((10,200), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    _, ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    images = []\n",
    "    flag=True\n",
    "    y1 = 10e5\n",
    "    y2 = -10e5 \n",
    "    height = 0 \n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        x, y, w, h = cv2.boundingRect(ctr) \n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        if(len(sum(roi))>200 and h>40): #20 is thershold you can change this, this is for small lines and points, remove them from return images \n",
    "            th, im_th_otsu = cv2.threshold(roi, 128, 192, cv2.THRESH_OTSU)\n",
    "            images.append(im_th_otsu)\n",
    "            y2=max(y2,y+h)\n",
    "            y1=min(y1,y) \n",
    "            \n",
    "    #--UnComment-- in case you want to return the whole  image not just lines \n",
    "    #if(y2>0):\n",
    "    #    croped = gray[y1:y2, ::]\n",
    "    #else:\n",
    "    #   croped = gray\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    testset=[]\n",
    "    trainingset=[]\n",
    "    labels=[]\n",
    "    histSet=[]\n",
    "    trainingset=[]\n",
    "    testsetHist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(pathToData='new data'):\n",
    "    global trainingset\n",
    "    global testset\n",
    "    global labels\n",
    "    global histSet\n",
    "    global trainingsetHist\n",
    "    global testsetHist\n",
    "    global predictedLabels\n",
    "\n",
    "    predictedLabels = []\n",
    "    \n",
    "    data= sorted(os.listdir(pathToData))\n",
    "    path=pathToData\n",
    "    for datafolder in data:\n",
    "        path+='/'+datafolder\n",
    "        imageFolders=os.listdir(path)\n",
    "        for imageFolder in sorted(imageFolders):\n",
    "            if(imageFolder=='test.png'):\n",
    "                testset.append(cv2.imread(path+'/'+imageFolder))\n",
    "            else:\n",
    "                trainingset.append([cv2.imread(path+'/'+imageFolder+'/1.png'),int(imageFolder)])\n",
    "                trainingset.append([cv2.imread(path+'/'+imageFolder+'/2.png'),int(imageFolder)])\n",
    "        path=pathToData\n",
    "        start = time.time()\n",
    "        for image in trainingset:\n",
    "            newImage=cutLines(image[0])\n",
    "            segments=lines_segments(newImage)\n",
    "            describe(segments,image[1])\n",
    "        random.shuffle(trainingsetHist)\n",
    "        for datatrain in trainingsetHist:\n",
    "            histSet.append(datatrain[0])\n",
    "            labels.append(datatrain[1])\n",
    "\n",
    "        #------------models-----------------------\n",
    "        #model = SVC(C=5, gamma='auto', probability=True)\n",
    "        #model= AdaBoostClassifier(n_estimators=250, random_state=0)\n",
    "        #model=GaussianNB()\n",
    "        #model=MultinomialNB()\n",
    "        #model= KNeighborsClassifier(n_neighbors=7)\n",
    "        model=RandomForestClassifier(max_depth=100,n_estimators=100, random_state=0)\n",
    "        #model = BaggingClassifier(n_estimators=100,random_state=0)\n",
    "        #model=MLPClassifier(solver='sgd',hidden_layer_sizes=(128, 16), random_state=0,max_iter=50000,learning_rate_init=0.0001)\n",
    "        #------------------------------------------\n",
    "        model.fit(histSet, labels)\n",
    "        newImage=cutLines(testset[0])\n",
    "        segments=lines_segments(newImage)\n",
    "        describe(segments,-1,1)\n",
    "        p = model.predict_proba(testsetHist)\n",
    "        p = np.sum(p, axis=0)\n",
    "        print(p)\n",
    "        y_pred = model.classes_[np.argmax(p)]\n",
    "        end = time.time()\n",
    "        \n",
    "        print(y_pred)\n",
    "        predictedLabels.append(y_pred)\n",
    "\n",
    "        result_file = open(\"results.txt\", 'a')\n",
    "        result_file.write(str(y_pred) +'\\n')\n",
    "        result_file.close()\n",
    "        \n",
    "        time_file = open(\"time.txt\", 'a')\n",
    "        t = (end - start)\n",
    "        time_file.write(str(round(t,2)) + '\\n')\n",
    "        time_file.close()\n",
    "\n",
    "        testset=[]\n",
    "        trainingset=[]\n",
    "        labels=[]\n",
    "        histSet=[]\n",
    "        trainingset=[]\n",
    "        testsetHist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global predictedLabels\n",
    "    path=str(input('please enter the path to the dataset file '))\n",
    "    run(pathToData=path)\n",
    "    true=[3, 3, 1, 2, 3]\n",
    "    totalCorrect=0\n",
    "    for i in range(len(predictedLabels)):\n",
    "        if predictedLabels[i]==true[i]:\n",
    "            totalCorrect+=1\n",
    "        else:\n",
    "            print(i)\n",
    "    print(totalCorrect/len(predictedLabels)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.44 0.84 5.72]\n",
      "3\n",
      "[1.83 0.89 2.28]\n",
      "3\n",
      "[9.53 0.72 0.75]\n",
      "1\n",
      "[0.57 9.25 0.18]\n",
      "2\n",
      "[0.65 1.11 7.24]\n",
      "3\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}